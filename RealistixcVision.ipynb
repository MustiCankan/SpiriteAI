{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOvWjpHuBJH4ZiwVQeqcSM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MustiCankan/SpiriteAI/blob/main/RealistixcVision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realistic Vision"
      ],
      "metadata": {
        "id": "oL0jg0UL2r_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading weights"
      ],
      "metadata": {
        "id": "ZCxjD2wQ2xEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers accelerate safetensors"
      ],
      "metadata": {
        "id": "ICvlb6Dm209T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhlGypX72qtn"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "# Run this before you deploy it on replicate\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "from diffusers import AutoencoderKL, StableDiffusionImg2ImgPipeline\n",
        "\n",
        "# append project directory to path so predict.py can be imported\n",
        "sys.path.append('.')\n",
        "from predict import MODEL_NAME, MODEL_CACHE, VAE_CACHE\n",
        "\n",
        "# Make cache folders\n",
        "if not os.path.exists(MODEL_CACHE):\n",
        "    os.makedirs(MODEL_CACHE)\n",
        "\n",
        "if not os.path.exists(VAE_CACHE):\n",
        "    os.makedirs(VAE_CACHE)\n",
        "\n",
        "url = \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.safetensors\"\n",
        "vae = AutoencoderKL.from_single_file(\n",
        "    url,\n",
        "    cache_dir=VAE_CACHE\n",
        ")\n",
        "\n",
        "\n",
        "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "pipe.save_pretrained(MODEL_CACHE, safe_serialization=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict"
      ],
      "metadata": {
        "id": "nu0JWK3j380U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction interface for Cog ⚙️\n",
        "from cog import BasePredictor, Input, Path\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "from PIL import Image\n",
        "from diffusers import AutoencoderKL, StableDiffusionImg2ImgPipeline\n",
        "import tempfile\n",
        "\n",
        "MODEL_NAME = \"SG161222/Realistic_Vision_V5.0_noVAE\"\n",
        "MODEL_CACHE = \"cache\"\n",
        "VAE_CACHE = \"vae-cache\"\n",
        "\n",
        "class Predictor(BasePredictor):\n",
        "    def setup(self):\n",
        "        \"\"\"Load the model into memory to make running multiple predictions efficient\"\"\"\n",
        "        vae = AutoencoderKL.from_single_file(\n",
        "            \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.safetensors\",\n",
        "            cache_dir=VAE_CACHE\n",
        "        )\n",
        "        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "            \"cache\",\n",
        "            vae=vae,\n",
        "        )\n",
        "        self.pipe = pipe.to(\"cuda\")\n",
        "\n",
        "    def scale_down_image(self, image_path, max_size):\n",
        "        #Open the Image\n",
        "        image = Image.open(image_path)\n",
        "        #Get the Original width and height\n",
        "        width, height = image.size\n",
        "        # Calculate the scaling factor to fit the image within the max_size\n",
        "        scaling_factor = min(max_size/width, max_size/height)\n",
        "        # Calaculate the new width and height\n",
        "        new_width = int(width * scaling_factor)\n",
        "        new_height = int(height * scaling_factor)\n",
        "        #resize the image\n",
        "        resized_image = image.resize((new_width, new_height))\n",
        "        cropped_image = self.crop_center(resized_image)\n",
        "        return cropped_image\n",
        "\n",
        "    def crop_center(self, pil_img):\n",
        "        img_width, img_height = pil_img.size\n",
        "        crop_width = self.base(img_width)\n",
        "        crop_height = self.base(img_height)\n",
        "        return pil_img.crop(\n",
        "                (\n",
        "                    (img_width - crop_width) // 2,\n",
        "                    (img_height - crop_height) // 2,\n",
        "                    (img_width + crop_width) // 2,\n",
        "                    (img_height + crop_height) // 2)\n",
        "                )\n",
        "\n",
        "    def base(self, x):\n",
        "        return int(8 * math.floor(int(x)/8))\n",
        "\n",
        "    def predict(\n",
        "        self,\n",
        "        image: Path = Input(description=\"Input image\"),\n",
        "        prompt: str = \"a latina woman with a pearl earring\",\n",
        "        negative_prompt: str = \"disfigured, kitsch, ugly, oversaturated, greain, low-res, deformed, blurry\",\n",
        "        steps: int = Input(description=\" num_inference_steps\", ge=0, le=50, default=30),\n",
        "        strength: float = Input(description=\"strength/weight\", ge=0, le=1, default=0.8),\n",
        "        seed: int = Input(description=\"Leave blank to randomize\",  default=None),\n",
        "    ) -> Path:\n",
        "        \"\"\"Run a single prediction on the model\"\"\"\n",
        "        if (seed == 0) or (seed == None):\n",
        "            seed = int.from_bytes(os.urandom(2), byteorder='big')\n",
        "        generator = torch.Generator('cuda').manual_seed(seed)\n",
        "        print(\"Using seed:\", seed)\n",
        "\n",
        "        r_image = self.scale_down_image(image, 1024)\n",
        "        image = self.pipe(\n",
        "            prompt=prompt,\n",
        "            image=r_image,\n",
        "            strength=strength,\n",
        "            negative_prompt=negative_prompt,\n",
        "            num_inference_steps=steps,\n",
        "            generator=generator,\n",
        "        ).images[0]\n",
        "        #Scale image\n",
        "        output_path = Path(tempfile.mkdtemp()) / \"output.png\"\n",
        "        image.save(output_path)\n",
        "        return Path(output_path)"
      ],
      "metadata": {
        "id": "p6nn7EF138f_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}